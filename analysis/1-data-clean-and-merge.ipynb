{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to recreate the treatment groups since seed was not set during original group assignment, using the email outcomes from GovDelivery, the email vendor we used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic  Email \n",
    "\n",
    "This section pulls in the email outcomes from GovDelivery for the employees in the basic email treatment group, and in addition to cleaning the files, this section assigns everyone in this group a 1 as their true treatment arm assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivered           11230\n",
      "Delivery Failure        1\n",
      "Name: Delivery Status_0118, dtype: int64\n",
      "\n",
      "Before drop: 11231\n",
      "After drop: 11230\n",
      "\n",
      "Delivered           11230\n",
      "Delivery Failure        1\n",
      "Name: Delivery Status_0123, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11231\n",
      "After drop: 11230\n",
      "Number of rows: 11230\n",
      "Delivered           11213\n",
      "Delivery Failure        3\n",
      "Name: Delivery Status_0212, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11216\n",
      "After drop: 11213\n",
      "Number of rows: 11230\n",
      "Delivered           11213\n",
      "Delivery Failure        3\n",
      "Name: Delivery Status_0301, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11216\n",
      "After drop: 11213\n",
      "Number of rows: 11230\n",
      "\n",
      "(11230, 36)\n"
     ]
    }
   ],
   "source": [
    "to_merge = [\n",
    "    'Basic_email_outcomes_012318',\n",
    "    'Basic_email_outcomes_021218',\n",
    "    'Basic_email_outcomes_030118'\n",
    "]\n",
    "\n",
    "## Importing Data\n",
    "basic = pd.read_csv(os.path.join(DATA_DIR, 'Basic_email_outcomes_011818.csv'))\n",
    "\n",
    "basic.columns = ['Destination Address', 'Delivery Status_0118', 'Failure Message_0118', \n",
    "                 'Opens0118', 'Clicks0118', 'Click0118_1', 'Click0118_2']\n",
    "\n",
    "## Transforming email to upper case for consistency\n",
    "basic['Destination Address'] = basic['Destination Address'].str.upper()\n",
    "\n",
    "## Assigning treatment designation\n",
    "basic['treatment_real'] = 1\n",
    "\n",
    "## Delete folks with emails designated 'NETWORK SUBSCRIBER'\n",
    "basic = basic[basic['Destination Address']!='NETWORK SUBSCRIBER']\n",
    "\n",
    "#Drop delivery failures - they should not be included in our total\n",
    "print (basic['Delivery Status_0118'].value_counts())\n",
    "print ('\\nBefore drop:', len(basic))\n",
    "basic = basic[basic['Delivery Status_0118'] == 'Delivered']\n",
    "print('After drop:', len(basic))\n",
    "print()\n",
    "\n",
    "\n",
    "## Reading in and cleaning in files via loops\n",
    "# the whole: i[-6:-2] refers to the date format in the file names, \n",
    "# and giving those same dates to our columns so we can distinguish clicks from one another\n",
    "# -6 = sixth char from end\n",
    "# -2 = second char from end\n",
    "\n",
    "for i in to_merge:\n",
    "    add = pd.read_csv(os.path.join(DATA_DIR, 'Basic_email_outcomes_'+i[-6:-2]+'18.csv'))\n",
    "\n",
    "    ncol = add.shape[1]\n",
    "    nclick = ncol - 5\n",
    "    cnames = ['Destination Address', 'Delivery Status_'+i[-6:-2], \n",
    "             'Failure Message_'+i[-6:-2], 'Opens'+i[-6:-2], 'Clicks'+i[-6:-2]]\n",
    "    \n",
    "    for n in range(1,nclick+1):\n",
    "        cnames.append('Click'+i[-6:-2]+'_'+str(n))\n",
    "            \n",
    "    add.columns = cnames        \n",
    "    add['Destination Address'] = add['Destination Address'].str.upper()\n",
    "    add = add[add['Destination Address']!='NETWORK SUBSCRIBER']\n",
    "    \n",
    "    \n",
    "    for n in range(1, nclick+1):\n",
    "        add['Click'+i[-6:-2]+'_'+str(n)] = add['Click'+i[-6:-2]+'_'+str(n)].str[:-4]\n",
    "    \n",
    "    add['in_'+i[-6:-2]] = 1\n",
    "    print(add['Delivery Status_'+i[-6:-2]].value_counts(), '\\n')\n",
    "    \n",
    "    print()\n",
    "    print('Dropping delivery failures:')\n",
    "    \n",
    "    print('Before drop:', len(add))\n",
    "    add = add[add['Delivery Status_'+i[-6:-2]] == 'Delivered']\n",
    "    print('After drop:', len(add))                  \n",
    "        \n",
    "    ## Merging \n",
    "    temp = basic.merge(add, how = 'left', on = ['Destination Address'])\n",
    "    temp['Destination Address'].value_counts(ascending = False).head()\n",
    "    print('Number of rows: '+str(temp.shape[0]))\n",
    "        \n",
    "    basic = temp\n",
    "    \n",
    "print('')    \n",
    "print(basic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Choice Email\n",
    "\n",
    "This section pulls in the email outcomes from GovDelivery for the employees in the simplified choice email treatment group, and in addition to cleaning the files, this section assigns everyone in this group a 2 as their true treatment arm assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivered           11234\n",
      "Delivery Failure        1\n",
      "Name: Delivery Status_0118, dtype: int64\n",
      "\n",
      "Before drop: 11235\n",
      "After drop 11234\n",
      "\n",
      "Enhance_email_outcomes_012318\n",
      "Delivered           11234\n",
      "Delivery Failure        1\n",
      "Name: Delivery Status_0123, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11235\n",
      "After drop: 11234\n",
      "Number of rows: 11234\n",
      "Enhance_email_outcomes_021218\n",
      "Delivered           11214\n",
      "Delivery Failure        2\n",
      "Name: Delivery Status_0212, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11216\n",
      "After drop: 11214\n",
      "Number of rows: 11234\n",
      "Enhance_email_outcomes_030118\n",
      "Delivered           11214\n",
      "Delivery Failure        2\n",
      "Name: Delivery Status_0301, dtype: int64 \n",
      "\n",
      "\n",
      "Dropping delivery failures:\n",
      "Before drop: 11216\n",
      "After drop: 11214\n",
      "Number of rows: 11234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_merge = [\n",
    "    'Enhance_email_outcomes_012318',\n",
    "    'Enhance_email_outcomes_021218',\n",
    "    'Enhance_email_outcomes_030118'\n",
    "]\n",
    "\n",
    "#initialize dataframes with first email group\n",
    "enhance = pd.read_csv(os.path.join(DATA_DIR, 'Enhance_email_outcomes_011818.csv'))\n",
    "\n",
    "enhance.columns = ['Destination Address', 'Delivery Status_0118', 'Failure Message_0118', \n",
    "                   'Opens0118', 'Clicks0118', 'Click0118_1', 'Click0118_2']\n",
    "\n",
    "#Change casing\n",
    "enhance['Destination Address'] = enhance['Destination Address'].str.upper()\n",
    "\n",
    "#Real treatment group assignment\n",
    "enhance['treatment_real'] = 2\n",
    "enhance = enhance[enhance['Destination Address']!='NETWORK SUBSCRIBER']\n",
    "\n",
    "print (enhance['Delivery Status_0118'].value_counts())\n",
    "\n",
    "print('\\nBefore drop:', len(enhance))\n",
    "enhance = enhance[enhance['Delivery Status_0118']== 'Delivered']\n",
    "print('After drop', len(enhance))\n",
    "print()\n",
    "\n",
    "\n",
    "## Reading in and cleaning in files via loops\n",
    "# the whole: i[-6:-2] refers to the date format in the file names, \n",
    "# and giving those same dates to our columns so we can distinguish clicks from one another\n",
    "# -6 = sixth char from end\n",
    "# -2 = second char from end\n",
    "\n",
    "for i in to_merge:\n",
    "    print(i)\n",
    "    \n",
    "    add = pd.read_csv(os.path.join(DATA_DIR, i+'.csv'))\n",
    "\n",
    "    ncol = add.shape[1]\n",
    "    nclick = ncol - 5\n",
    "    cnames = ['Destination Address', 'Delivery Status_'+i[-6:-2], 'Failure Message_'+i[-6:-2], \n",
    "              'Opens'+i[-6:-2], 'Clicks'+i[-6:-2]]\n",
    "    \n",
    "    for n in range(1,nclick+1):\n",
    "        cnames.append('Click'+i[-6:-2]+'_'+str(n))\n",
    "        \n",
    "    add.columns = cnames        \n",
    "    add['Destination Address'] = add['Destination Address'].str.upper()\n",
    "    add = add[add['Destination Address']!='NETWORK SUBSCRIBER']\n",
    "    \n",
    "    for n in range(1, nclick+1):\n",
    "        add['Click'+i[-6:-2]+'_'+str(n)] = add['Click'+i[-6:-2]+'_'+str(n)].str[:-4]\n",
    "    \n",
    "    #Add a 1 to represent that it was in this particular csv\n",
    "    add['in_'+i[-6:-2]] = 1\n",
    "    \n",
    "    print(add['Delivery Status_'+i[-6:-2]].value_counts(),'\\n')\n",
    "    \n",
    "    print()\n",
    "    print('Dropping delivery failures:')\n",
    "    print('Before drop:', len(add))\n",
    "    add = add[add['Delivery Status_' + i[-6:-2]] == 'Delivered']\n",
    "    print('After drop:', len(add))\n",
    "    \n",
    "    \n",
    "    ## Merging \n",
    "    temp = enhance.merge(add, how = 'left', on = ['Destination Address'])\n",
    "    temp['Destination Address'].value_counts(ascending = False).head()\n",
    "    print('Number of rows: '+str(temp.shape[0]))\n",
    "        \n",
    "    enhance = temp\n",
    "print('')    \n",
    "#print(enhance.shape)\n",
    "#print(enhance.email_upper.value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control\n",
    "\n",
    "This section pulls in the email outcomes from GovDelivery for the employees in the control group. However these people are the ones whose emails did not work for the email sends, so they will be dropped from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = [\n",
    "    'Control_deleted_subscribers_021218',\n",
    "    'control_unsubscribe_031618'\n",
    "]\n",
    "\n",
    "#Read in files\n",
    "control = pd.read_csv(os.path.join(DATA_DIR, 'Control_Deleted_012318.csv'))\n",
    "control.columns = ['Destination Address', 'temp', 'Failure Message_0123']\n",
    "\n",
    "control['Destination Address'] = control['Destination Address'].str.upper()\n",
    "control['Delivery Status_0123'] = 'Deleted'\n",
    "control = control.drop(['temp'], axis=1)\n",
    "print (control.shape)\n",
    "print (control['Delivery Status_0123'].value_counts())\n",
    "control.head().T\n",
    "\n",
    "for i in to_merge:\n",
    "    add = pd.read_csv(os.path.join(DATA_DIR, i +'.csv'))\n",
    "\n",
    "    cnames = ['Destination Address', 'temp', 'Failure Message_'+i[-6:-2]]\n",
    "        \n",
    "    add.columns = cnames        \n",
    "    add['Destination Address'] = add['Destination Address'].str.upper()\n",
    "\n",
    "    add = add[add['Destination Address']!='NETWORK SUBSCRIBER']\n",
    "    add['in_'+i[-6:-2]] = 1\n",
    "        \n",
    "    # Fix here so that we're appending, and not merging\n",
    "    # Each file has a different email address, so merging doesn't do anything. \n",
    "    temp = control.append(add)\n",
    "    temp['Destination Address'].value_counts(ascending = False).head()\n",
    "    print('Number of rows: '+str(temp.shape[0]))\n",
    "        \n",
    "    control = temp\n",
    "    control['treatment_real'] = 0\n",
    "    \n",
    "print('')    \n",
    "print(control.shape)\n",
    "# print(control['Destination Address'].value_counts())\n",
    "\n",
    "# Output cleared since it contained emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsuccessful emails\n",
    "\n",
    "Pull in the unsuccessful emails. When we uploaded the email lists to gov delivery, these were the folks who were unable to receive emails. Since we know which group they were supposed to have been assigned to, we need to remember to take them out of the control group later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unsuccessful emails:\n",
      "\n",
      "Control: 175\n",
      "Basic: 187\n",
      "Simplified: 176\n",
      "Total unsuccessful: 538\n"
     ]
    }
   ],
   "source": [
    "#These were all of the unsuceessful emails\n",
    "#Read: When we uploaded the email lists to gov delivery, these were the folks who were unable to receive emails\n",
    "\n",
    "basic_unsuccessful = pd.read_csv(os.path.join(DATA_DIR, 'basic_unsuccessful.csv'))\n",
    "simplified_unsuccessful = pd.read_csv(os.path.join(DATA_DIR, 'enhance_unsuccessful.csv'))\n",
    "control_unsuccessful = pd.read_csv(os.path.join(DATA_DIR, 'control_unsuccessful.csv'))\n",
    "\n",
    "print('Number of unsuccessful emails:\\n')\n",
    "print('Control:', len(control_unsuccessful))\n",
    "print('Basic:', len(basic_unsuccessful))\n",
    "print('Simplified:', len(simplified_unsuccessful))\n",
    "\n",
    "#Concatenate all files\n",
    "failures = basic_unsuccessful.append(simplified_unsuccessful).append(control_unsuccessful)\n",
    "\n",
    "#change to a consistent casing\n",
    "failures['destination'] = failures.destination.str.upper()\n",
    "\n",
    "print('Total unsuccessful:', len(failures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Duplicates\n",
    "\n",
    "There are ~27 employees who have duplicate entries in the dataset. This is due to these employees being associated with the emails OSSE.HR@DC.GOV or OCTOQA1@DC.GOV or OSSE.DOTHR@DC.GOV. It turns out that these employees received both the basic and simplified choice treatments. As a result, we have decided to drop them from the dataset because we would not be able to determine whether their choice to enroll or unenroll in 457b is a result of which treatment arm.\n",
    "\n",
    "In addition, somehow Lab staff were still included in these email sends, so we need to make sure to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling bad OSSE data\n",
    "\n",
    "#OSSE data + The list of Lab staff still active during the time of the study\n",
    "\n",
    "\n",
    "bad_emails_list = ['OCTOQA1@DC.GOV', \n",
    "              'OSSE.HR@DC.GOV', \n",
    "              'OSSE.DOTHR@DC.GOV']\n",
    "\n",
    "#### NOTE: Our private repo include the actual emails for Lab and DCHR staff, but due to PII\n",
    "#### we do not include the actual list items here\n",
    "lab_emails = []\n",
    "dchr_emails = []\n",
    "\n",
    "bad_emails_init = bad_emails_list + lab_emails + dchr_emails\n",
    "\n",
    "#uppercase for consistency\n",
    "bad_emails = [x.upper() for x in bad_emails_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11216\n",
      "2    11219\n",
      "Name: treatment_real, dtype: int64\n",
      "(22435, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "#Combine the results from the two treatment groups \n",
    "all_email_outcomes = basic.append(enhance)\n",
    "\n",
    "#Renaming column name, bc it was previously \"email_upper\" beforehand, \n",
    "#and I don't want to change the code in the other notebooks\n",
    "all_email_outcomes.rename(columns={'Destination Address': 'email_upper'}, inplace = True)\n",
    "\n",
    "#Remove the bad emails from our data.\n",
    "all_email_outcomes = all_email_outcomes[~all_email_outcomes.email_upper.isin(bad_emails)]\n",
    "\n",
    "#What does our data look like? \n",
    "print(all_email_outcomes.treatment_real.value_counts(sort = False))\n",
    "print(all_email_outcomes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join to baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: Breakout by treatment arm:\n",
      "treatment  Enrollment\n",
      "0          NaN           7150\n",
      "           457BEN        4262\n",
      "1          NaN           7153\n",
      "           457BEN        4261\n",
      "2          NaN           7151\n",
      "           457BEN        4262\n",
      "Name: Enrollment, dtype: int64\n",
      "\n",
      "Total by treatment arm:\n",
      "0    11412\n",
      "1    11414\n",
      "2    11413\n",
      "Name: treatment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "df_ids = pd.read_csv(os.path.join(DATA_DIR, 'baseline.csv'), dtype = {\"EmplID\":str})\n",
    "\n",
    "#change casing for easy merging, plus rename\n",
    "df_ids['email_upper'] = df_ids['Email ID'].str.upper()\n",
    "\n",
    "#Some of the bad OSSE emails were in our baseline, so let's get rid of them. \n",
    "df_ids = df_ids[~df_ids.email_upper.isin(bad_emails)]\n",
    "\n",
    "print('Original Data: Breakout by treatment arm:')\n",
    "print(df_ids.groupby('treatment')['Enrollment'].value_counts(dropna = False))\n",
    "\n",
    "print()\n",
    "print('Total by treatment arm:')\n",
    "#Totals by group\n",
    "print(df_ids.treatment.value_counts(sort = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34239, 62)\n"
     ]
    }
   ],
   "source": [
    "#Merge email data to our baseline data\n",
    "#Indicator = True, so that the people who were not in our email outcomes will be assigned as our control group.\n",
    "outcomes = pd.merge(df_ids, \n",
    "                    all_email_outcomes, \n",
    "                    how = 'left', \n",
    "                    on = 'email_upper',\n",
    "                    indicator = True)\n",
    "\n",
    "outcomes.loc[outcomes._merge =='left_only', 'treatment_real'] = 0\n",
    "\n",
    "print(outcomes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    11258\n",
      "1.0    11217\n",
      "2.0    11223\n",
      "Name: treatment_real, dtype: int64\n",
      "\n",
      "treatment_real  Enrollment\n",
      "0.0             NaN           7032\n",
      "                457BEN        4226\n",
      "1.0             NaN           7022\n",
      "                457BEN        4195\n",
      "2.0             NaN           7027\n",
      "                457BEN        4196\n",
      "Name: Enrollment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Remove the employees that were in our failed email delivery list from above\n",
    "outcomes = (outcomes[~((outcomes.email_upper.isin(failures.destination.str.upper()))|\\\n",
    "                    (outcomes.email_upper.isin(control['Destination Address'])))])\n",
    "\n",
    "print(outcomes.treatment_real.value_counts(sort = False) )\n",
    "print()\n",
    "print(outcomes.groupby('treatment_real')['Enrollment'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33686, 62)\n",
      "\n",
      "0.0    11256\n",
      "1.0    11215\n",
      "2.0    11215\n",
      "Name: treatment_real, dtype: int64\n",
      "\n",
      "treatment_real  Enrollment\n",
      "0.0             NaN           7031\n",
      "                457BEN        4225\n",
      "1.0             NaN           7021\n",
      "                457BEN        4194\n",
      "2.0             NaN           7021\n",
      "                457BEN        4194\n",
      "Name: Enrollment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outcomes = (outcomes[~outcomes.email_upper.duplicated(keep=False)])\n",
    "print(outcomes.shape)\n",
    "\n",
    "print()\n",
    "print(outcomes.treatment_real.value_counts(sort = False))\n",
    "print()\n",
    "print(outcomes.groupby('treatment_real')['Enrollment'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns. \n",
    "outcomes = outcomes.drop(labels = ['treatment', '_merge', 'Email ID', \n",
    "                                   'Last Name', 'First Name', 'Empl Record'], \n",
    "                         axis = 1)\n",
    "\n",
    "outcomes.to_csv(os.path.join(DATA_DIR, 'outcomes_id_emails.csv'), \n",
    "                index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
